{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Kaggle: How Much Did It Rain\n",
      "URL: https://www.kaggle.com/c/how-much-did-it-rain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import collections\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import f_regression\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import make_scorer\n",
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(precision=3)\n",
      "np.set_printoptions(suppress=True)\n",
      "np.set_printoptions(linewidth=130)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Helpful functions\n",
      "Includes __Vectorizers__ used to vectorize data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "cimport numpy as np\n",
      "import numpy as np\n",
      "\n",
      "class Vectorizer(object):\n",
      "\n",
      "    \"\"\"Turn a matrix into a vector\n",
      "    \"\"\"\n",
      "    @staticmethod\n",
      "    def get_all():\n",
      "        return Vectorizer.__subclasses__()\n",
      "\n",
      "class IntegrationMethod(Vectorizer):\n",
      "\n",
      "    \"\"\"Produce a vector which is the trapizoidally integrated quanties.\n",
      "    \"\"\"\n",
      "    @staticmethod\n",
      "    def vectorize(mat):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        a = np.zeros(mat.shape[0]-1, dtype=np.float)\n",
      "        a += mat[1:,0] * (60 - mat[0, 0]) + mat[1:,-1] * (mat[0, -1])\n",
      "        for i in xrange(mat.shape[1]-1):\n",
      "            a += 0.5 * (mat[0, i] - mat[0, i+1]) * (mat[1:, i] + mat[1:, i+1])\n",
      "        return a\n",
      "\n",
      "class MeanMethod(Vectorizer):\n",
      "\n",
      "    \"\"\"Produce a vector which is the mean of quanties.\n",
      "    \"\"\"\n",
      "    @staticmethod\n",
      "    def vectorize(mat):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        return np.mean(mat[1:, :], axis=1)\n",
      "\n",
      "class DifferenceMethod(Vectorizer):\n",
      "\n",
      "    \"\"\"Produce a vector which is the difference of start and stop quantities.\n",
      "    \"\"\"\n",
      "    @staticmethod\n",
      "    def vectorize(mat):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        return mat[1:, -1] - mat[1:, 0]\n",
      "    \n",
      "def parseline(str text, columns):\n",
      "    \"\"\"Parse data line and turn it into a matrix.\n",
      "    \"\"\"\n",
      "    nanzero = lambda x: x if not np.isnan(x) else 0\n",
      "    text = text.rstrip()\n",
      "    cdef unsigned int index = 0\n",
      "    cdef float expected = 0\n",
      "    data_cols = []\n",
      "    cdef unsigned int i = 0\n",
      "    for i, col in enumerate(text.split(',')):\n",
      "        if columns[i] == 'Id':\n",
      "            index = int(col)\n",
      "        elif columns[i] == 'Expected':\n",
      "            expected = float(col)\n",
      "        elif columns[i] == 'LogWaterVolume':\n",
      "            data_cols.append([nanzero(np.exp(float(x))) for x in col.split(' ')])\n",
      "        else:\n",
      "            data_cols.append([nanzero(float(x)) for x in col.split(' ')])\n",
      "    return (index, np.array(data_cols, dtype=float), expected)\n",
      "\n",
      "def accumulate(class_weights, size=70):\n",
      "    \"\"\"Produce a CDF from weighted classes.\n",
      "    \"\"\"\n",
      "    cdf = np.zeros(size)\n",
      "    for i, j in class_weights:\n",
      "        if i >= size:\n",
      "            break\n",
      "        cdf[i] += j\n",
      "    for i in xrange(1, cdf.shape[0]):\n",
      "        cdf[i] += cdf[i-1]\n",
      "    return cdf\n",
      "\n",
      "heaviside = lambda x: 1 if x >= 0 else 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read in data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_data = []\n",
      "data_fh = open('data/train_2013_medium.csv', 'r')\n",
      "columns = data_fh.readline().rstrip().split(',')\n",
      "\n",
      "for i, line in enumerate(data_fh.readlines()):\n",
      "    if i % 100000 == 0:\n",
      "        print \"Read {:6d} measurments\".format(i)\n",
      "    raw_data.append(parseline(line, columns))\n",
      "    \n",
      "print \"Data points: \", len(raw_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Read      0 measurments\n",
        "Read 100000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 200000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 300000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 400000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 500000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 600000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 700000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 800000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 900000 measurments"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Data points: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000000\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Vectorize Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([np.concatenate([vectorizer.vectorize(hs[1]) for vectorizer in Vectorizer.get_all()]) \n",
      "              for hs in raw_data])\n",
      "\n",
      "Y = np.array([int(np.ceil(x[2])) for x in raw_data])\n",
      "\n",
      "#del raw_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scorer\n",
      "\n",
      "$$\n",
      "score = \\sum_N \\sum_{n=1}^{70} ( (P(y \\le n)) - H(n - z))^2\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crps(est, X, y, **kwargs):\n",
      "    \"\"\"Continuous Ranked Probability Score\n",
      "    \"\"\"\n",
      "    classes = est.named_steps['clf'].classes_\n",
      "    \n",
      "    cdfs = [accumulate(zip(classes, z)) for z in est.predict_proba(X)]\n",
      "    N = len(cdfs)\n",
      "    M = len(cdfs[0])\n",
      "    tot = 0\n",
      "    for i, cdf in enumerate(cdfs):\n",
      "        for n in xrange(M):\n",
      "            tot += (cdf[n] - heaviside(n - y[i])) ** 2\n",
      "    return -float(tot) / (M * N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define pipeline, CV Parameters and run grid search fit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = Pipeline([('scaler', StandardScaler()), \n",
      "          ('decomp', PCA(n_components=0.9)),\n",
      "          #('anova', SelectKBest(f_regression)),\n",
      "          ('clf', SVC(probability=True))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {\n",
      "              'decomp__n_components': [0.99],\n",
      "              #'anova__k': [5, 10],\n",
      "              'clf__C': [1, 3, 10, 30],\n",
      "              #'clf__penalty': ['l1', 'l2'],\n",
      "              'clf__gamma': [0, 0.1, 0.3, 1.0 ],\n",
      "              'clf__degree': [ 3, 4, 5],\n",
      "              }\n",
      "clf = GridSearchCV(pipeline, parameters, verbose=1, n_jobs=2, scoring=crps)\n",
      "clf.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key, val in  clf.best_params_.iteritems():\n",
      "    print \"{:20} => {}\".format(key, val)\n",
      "print \"Best Score =\", clf.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Process Testing Data and write to CSV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_data(dat):\n",
      "    return np.concatenate([vectorizer.vectorize(dat) for vectorizer in Vectorizer.get_all()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data_fh = open('data/test_2014.csv', 'r')\n",
      "test_results_fh = open('data/test_2014_results.csv', 'w')\n",
      "\n",
      "writer = csv.writer(test_results_fh, delimiter=',')\n",
      "test_columns = test_data_fh.readline().rstrip().split(',')\n",
      "writer.writerow(['Id'] + ['Predicted{0}'.format(t) for t in xrange(0, 70)])\n",
      "\n",
      "\n",
      "classes = np.unique(clf.predict(X))\n",
      "\n",
      "for line in test_data_fh.readlines():\n",
      "    i, dat, _ =  parseline(line, test_columns)\n",
      "    cdf = accumulate(zip(classes, clf.predict_proba(vectorize_data(dat))[0]))\n",
      "    writer.writerow([i] + list(cdf))\n",
      "test_data_fh.close()\n",
      "test_results_fh.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_data[0][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}